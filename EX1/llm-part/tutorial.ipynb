{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-17T18:36:06.849599110Z",
     "start_time": "2023-11-17T18:36:05.070047205Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset lambada (/home/me/.cache/huggingface/datasets/lambada/plain_text/1.1.0/2e4879aaaa342d8f748b7275991006d2e27a8b0abc0a28ea299b3e3b839a3a40)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d37ba440c6434c00bd2d8cbd436d92e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"Column description not in the dataset. Current columns in the dataset: ['text', 'domain']\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 7\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dataset\n\u001B[1;32m      5\u001B[0m dataset \u001B[38;5;241m=\u001B[39m load_dataset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlambada\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m test_data \u001B[38;5;241m=\u001B[39m dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/py3-11/lib/python3.11/site-packages/datasets/arrow_dataset.py:2778\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   2776\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[1;32m   2777\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[0;32m-> 2778\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem(key)\n",
      "File \u001B[0;32m~/anaconda3/envs/py3-11/lib/python3.11/site-packages/datasets/arrow_dataset.py:2762\u001B[0m, in \u001B[0;36mDataset._getitem\u001B[0;34m(self, key, **kwargs)\u001B[0m\n\u001B[1;32m   2760\u001B[0m format_kwargs \u001B[38;5;241m=\u001B[39m format_kwargs \u001B[38;5;28;01mif\u001B[39;00m format_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[1;32m   2761\u001B[0m formatter \u001B[38;5;241m=\u001B[39m get_formatter(format_type, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info\u001B[38;5;241m.\u001B[39mfeatures, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mformat_kwargs)\n\u001B[0;32m-> 2762\u001B[0m pa_subtable \u001B[38;5;241m=\u001B[39m query_table(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data, key, indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indices \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indices \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m   2763\u001B[0m formatted_output \u001B[38;5;241m=\u001B[39m format_table(\n\u001B[1;32m   2764\u001B[0m     pa_subtable, key, formatter\u001B[38;5;241m=\u001B[39mformatter, format_columns\u001B[38;5;241m=\u001B[39mformat_columns, output_all_columns\u001B[38;5;241m=\u001B[39moutput_all_columns\n\u001B[1;32m   2765\u001B[0m )\n\u001B[1;32m   2766\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "File \u001B[0;32m~/anaconda3/envs/py3-11/lib/python3.11/site-packages/datasets/formatting/formatting.py:575\u001B[0m, in \u001B[0;36mquery_table\u001B[0;34m(table, key, indices)\u001B[0m\n\u001B[1;32m    573\u001B[0m     _raise_bad_key_type(key)\n\u001B[1;32m    574\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m--> 575\u001B[0m     _check_valid_column_key(key, table\u001B[38;5;241m.\u001B[39mcolumn_names)\n\u001B[1;32m    576\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    577\u001B[0m     size \u001B[38;5;241m=\u001B[39m indices\u001B[38;5;241m.\u001B[39mnum_rows \u001B[38;5;28;01mif\u001B[39;00m indices \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m table\u001B[38;5;241m.\u001B[39mnum_rows\n",
      "File \u001B[0;32m~/anaconda3/envs/py3-11/lib/python3.11/site-packages/datasets/formatting/formatting.py:515\u001B[0m, in \u001B[0;36m_check_valid_column_key\u001B[0;34m(key, columns)\u001B[0m\n\u001B[1;32m    513\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_valid_column_key\u001B[39m(key: \u001B[38;5;28mstr\u001B[39m, columns: List[\u001B[38;5;28mstr\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    514\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m columns:\n\u001B[0;32m--> 515\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumn \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in the dataset. Current columns in the dataset: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcolumns\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"Column description not in the dataset. Current columns in the dataset: ['text', 'domain']\""
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/datasets/lambada\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"lambada\")\n",
    "\n",
    "test_data = dataset['test']['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 19:25:25.775125: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95401423342d4c40927b00bf16f1e995"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d87427df6794cecb7fad7c5a720b8fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec22183f5bf54a60b61c1aaae58340dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4faa67cdfc414b5d97f832b2895e63e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa5ac8a88ade40d2b93cb9065d7267f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4904bcecec4b4fb782241d1e1b607f90"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce8fba1484ec450dab8f5fab12baac9d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://huggingface.co/mhemetfaik/flan-t5-large-copy#usage\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text2text-generation\", model=\"mhemetfaik/flan-t5-large-copy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T18:27:12.994293931Z",
     "start_time": "2023-11-17T18:25:24.393325230Z"
    }
   },
   "id": "beff314ae79d6ed6"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mhemetfaik/flan-t5-large-copy\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mhemetfaik/flan-t5-large-copy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T18:28:12.966968694Z",
     "start_time": "2023-11-17T18:28:07.855500820Z"
    }
   },
   "id": "5883efc6301e03e6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/me/anaconda3/envs/py3-11/lib/python3.11/site-packages/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Wie alte sind Sie?</s>\n"
     ]
    }
   ],
   "source": [
    "input_text = \"translate English to German: How old are you?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T18:28:22.062359567Z",
     "start_time": "2023-11-17T18:28:21.199223849Z"
    }
   },
   "id": "177c278c865f15ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bfecf6aad9543a3d"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'zoo'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict('today i want to go to the')[0]['generated_text']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T18:31:00.877054133Z",
     "start_time": "2023-11-17T18:31:00.329681335Z"
    }
   },
   "id": "21d605a7fb75593"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "aee6f9e0ad855bc0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
